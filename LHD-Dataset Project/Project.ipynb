{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "medieval-express",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\singh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\singh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\singh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\singh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\singh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\singh\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "necessary-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "electric-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./spam.csv', encoding='ISO-8859-1')\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interested-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "expensive-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the rows and column no 0\n",
    "y = data[:, 0]\n",
    "X = data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "imported-mexican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572,), (5572,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "above-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "sw = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "irish-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStemmedReview(review):\n",
    "    review = review.lower()\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "\n",
    "    # removing the stopwords\n",
    "    new_tokens = [token for token in tokens if token not in sw]\n",
    "    \n",
    "    # stemming\n",
    "    stemmed_tokens = [ps.stem(token) for token in new_tokens]\n",
    "    \n",
    "    cleaned_review = ' '.join(stemmed_tokens)\n",
    "\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "equivalent-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStemmedDocument(document):\n",
    "    d = []\n",
    "    for doc in document:\n",
    "        d.append(getStemmedReview(doc))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cathedral-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_document = getStemmedDocument(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "organized-petersburg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri 2 wkli comp win fa cup final tkt 21st may 2005 text fa 87121 receiv entri question std txt rate c appli 08452810075over18',\n",
       " 'u dun say earli hor u c alreadi say',\n",
       " 'nah think goe usf live around though',\n",
       " 'freemsg hey darl 3 week word back like fun still tb ok xxx std chg send å 1 50 rcv',\n",
       " 'even brother like speak treat like aid patent',\n",
       " 'per request mell mell oru minnaminungint nurungu vettam set callertun caller press 9 copi friend callertun',\n",
       " 'winner valu network custom select receivea å 900 prize reward claim call 09061701461 claim code kl341 valid 12 hour',\n",
       " 'mobil 11 month u r entitl updat latest colour mobil camera free call mobil updat co free 08002986030']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_document[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "superb-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "flexible-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_corpus = cv.fit_transform(stemmed_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "improved-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorized_corpus.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "processed-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "severe-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "coupled-french",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "generic-astronomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977705274605764"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "smooth-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"\"\"Hey there, Utkarsh  –\n",
    "WOWEE we are halfway through Local Hack Day: Build! Keep up the awesome work and build to your heart's content!\n",
    "There is still time for your friends to join in on the fun. Tell them to head over to the registration page and sign up now!\n",
    "Bonus! If you refer a friend to LHD: Build, have them complete hackp.ac/LHDBuildReferral. They'll earn a point, and so will you!\n",
    "Check in for Day 4 starts at 12 PM ET, so make sure to check that off your list so you can earn your extra hex stickers. \n",
    "There are also new live sessions and daily challenges today. Take a peep at those! \"\"\",\n",
    "    \n",
    "    \n",
    "    \"\"\"Join us today at 12:00 PM ET / 16:00 UTC for a Red Hat DevNation tech talk on AWS Lambda and serverless Java with Bill Burke.\n",
    "Have you ever tried Java on AWS Lambda but found that the cold-start latency and memory usage were far too high? \n",
    "In this session, we will show how we optimized Java for serverless applications by leveraging GraalVM with Quarkus to \n",
    "provide both supersonic startup speed and a subatomic memory footprint.\"\"\",\n",
    "\n",
    "    \"\"\"We really appreciate your interest and wanted to let you know that we have received your application.\n",
    "There is strong competition for jobs at Intel, and we receive many applications. As a result, it may take some time to get back to you.\n",
    "Whether or not this position ends up being a fit, we will keep your information per data retention policies, \n",
    "so we can contact you for other positions that align to your experience and skill set.\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "organic-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_message(messages):\n",
    "    d = getStemmedDocument(messages)\n",
    "    # very very import, dont do fit_transform!\n",
    "    return cv.transform(d)\n",
    "\n",
    "messages = prepare_message(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "productive-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "classical-microwave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-roots",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
